{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data\n",
    "def scale(X, X_min, X_max):\n",
    "    return (X - X_min)/(X_max-X_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_inputs_from_file(fileName): # Read in data\n",
    "    inputs = np.loadtxt(fileName, delimiter=' ')\n",
    "    X, _Y = inputs[:, :NUM_FEATURES], inputs[:, -1].astype(int)\n",
    "    X = scale(X, np.min(X, axis=0), np.max(X, axis=0))\n",
    "    _Y[_Y == 7] = 6 # Actually dont have, just in case have error data\n",
    "\n",
    "    Y = np.zeros((_Y.shape[0], NUM_CLASSES))\n",
    "    Y[np.arange(_Y.shape[0]), _Y - 1] = 1 #one hot matrix\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(feature_no, neuron_no, name, logistic = True):\n",
    "    # From eg.5.2\n",
    "    n_in = feature_no\n",
    "    n_out = neuron_no\n",
    "    W_values = np.asarray(np.random.uniform(low=-np.sqrt(6. / (n_in + n_out)),\n",
    "                                            high=np.sqrt(6. / (n_in + n_out)),\n",
    "                                            size=(n_in, n_out)))\n",
    "    if logistic == True:\n",
    "        W_values *= 4\n",
    "    return(tf.Variable(W_values, dtype=tf.float32, name=name))\n",
    "\n",
    "def init_bias(neuron_no, name):\n",
    "    # From eg.5.2\n",
    "    return(tf.Variable(np.zeros(neuron_no), dtype=tf.float32, name=name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Values\n",
    "NUM_FEATURES = 36\n",
    "NUM_CLASSES = 6\n",
    "NUM_HIDDEN = 10\n",
    "\n",
    "LEARNING_RATE = 0.01\n",
    "EPOCHS = 5000\n",
    "BATCH_SIZE = 32\n",
    "NUM_NEURONS = 10\n",
    "SEED = 10\n",
    "BETA = pow(10, -6)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "TRAIN_FILE_NAME = 'sat_train.txt'\n",
    "TEST_FILE_NAME = 'sat_test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainY = process_inputs_from_file(TRAIN_FILE_NAME)\n",
    "testX, testY = process_inputs_from_file(TEST_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_cross_entropy(labels, logits):\n",
    "    return tf.nn.softmax_cross_entropy_with_logits_v2(labels=labels, logits=logits)\n",
    "\n",
    "def setup_correct_prediction(labels, logits):\n",
    "    return tf.cast(tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1)), tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, NUM_FEATURES], name='x')\n",
    "d = tf.placeholder(tf.float32, [None, NUM_CLASSES], name='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"Hidden_layer\"):\n",
    "    W = init_weights(NUM_FEATURES, NUM_HIDDEN, name=\"Weight_1\")\n",
    "    b = init_bias(NUM_HIDDEN, name=\"Bias_1\")\n",
    "    z = tf.matmul(x, W) + b #syn_input_1\n",
    "    h = tf.nn.sigmoid(z) #out_1\n",
    "\n",
    "with tf.variable_scope(\"Output_layer\"):\n",
    "    V = init_weights(NUM_HIDDEN, NUM_CLASSES, name=\"Weight_2\")\n",
    "    c = init_bias(NUM_CLASSES, name=\"Bias_2\" )\n",
    "    y = tf.matmul(h, V) + c #syn_out_2\n",
    "    f = y #out_2\n",
    "\n",
    "cross_entropy = setup_cross_entropy(labels=d, logits=y)\n",
    "regularization = tf.nn.l2_loss(V) + tf.nn.l2_loss(W) \n",
    "J = tf.reduce_mean(cross_entropy + BETA * regularization)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(LEARNING_RATE)\n",
    "train_op = optimizer.minimize(J)\n",
    "\n",
    "correct_prediction = setup_correct_prediction(labels=d, logits=y)\n",
    "accuracy = tf.reduce_mean(correct_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(X_in, y_in, batch_size):\n",
    "    X = list(X_in)\n",
    "    y = list(y_in)\n",
    "    \n",
    "    if len(X)!=len(y):\n",
    "        print(\"Error: len(X)!=len(Y)\")\n",
    "        return None\n",
    "    batched_X = []\n",
    "    batched_y = []\n",
    "    count = 0\n",
    "    while (len(X) >= batch_size):\n",
    "        batched_X.append(X[0:batch_size])\n",
    "        del X[0:batch_size]\n",
    "        batched_y.append(y[0:batch_size])\n",
    "        del y[0:batch_size]\n",
    "        if count % 10 == 0:\n",
    "            print (count)\n",
    "        count += 1\n",
    "    \n",
    "    if len(X) != 0:\n",
    "        remain = batch_size-len(X)\n",
    "        X.extend(batched_X[0][0:remain])\n",
    "        y.extend(batched_y[0][0:remain])\n",
    "        batched_X.append(X)\n",
    "        batched_y.append(y)\n",
    "        print(\"Remain rescaled to\", len(X))\n",
    "    \n",
    "    return (batched_X, batched_y)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "Remain rescaled to 32\n"
     ]
    }
   ],
   "source": [
    "X, y = generate_batch(trainX, trainY, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8125    , 0.8       , 0.76190476, 0.50413223, 0.70967742,\n",
       "       0.68181818, 0.58947368, 0.390625  , 0.6875    , 0.72815534,\n",
       "       0.54736842, 0.421875  , 0.98387097, 0.95192308, 0.86956522,\n",
       "       0.59322034, 0.8125    , 0.82524272, 0.74698795, 0.41463415,\n",
       "       0.69230769, 0.73786408, 0.6       , 0.416     , 0.96875   ,\n",
       "       0.95192308, 0.93103448, 0.58333333, 0.75384615, 0.93069307,\n",
       "       0.82105263, 0.5546875 , 0.6875    , 0.77669903, 0.66315789,\n",
       "       0.453125  ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********* BEFORE **********\n",
      "[[ 0.783916   -1.3846724   0.38614455  0.7188592  -0.00431363 -0.7951342\n",
      "  -0.872375    0.7527411  -0.956025   -1.1893935 ]\n",
      " [ 0.5355528   1.3099715  -1.4332227   0.03522662  0.90324336  0.3251171\n",
      "   0.64070886 -0.60132426  1.2070583   0.6199653 ]\n",
      " [ 0.12292176 -1.0338639  -0.36595154  0.5031174  -0.16805911 -0.19065076\n",
      "   0.34025946  0.03795981  0.43453664  0.29192784]\n",
      " [ 0.8818693   0.06254426  1.180693   -0.522274   -1.1832696  -0.57582945\n",
      "  -1.1152997   0.94964594 -1.3091346   0.36487648]\n",
      " [ 0.1374888   0.9225033  -0.869819    1.0310335  -0.42861417  0.7357435\n",
      "  -0.5895198   1.1092925  -0.50414234 -0.96785635]\n",
      " [-0.310511   -1.1745988   0.92775786 -1.0079126  -0.33482355  1.283585\n",
      "   1.408877   -0.12624754  0.9422538  -0.71834487]\n",
      " [ 0.28133205  1.1638858   0.09984691  0.26061523 -1.331135   -0.4126391\n",
      "  -1.2146072  -0.562077   -0.48909602  0.7911671 ]\n",
      " [-1.3291776  -0.20371546 -0.5347245   0.39435846 -0.4439431  -1.3201108\n",
      "   1.0976739   0.76057065  1.0924197  -0.23833758]\n",
      " [ 0.30504107  0.03890859  0.28267556 -0.6870209  -0.57533467 -1.3712436\n",
      "  -0.5690036  -0.74521     0.16635838  0.18926685]\n",
      " [-0.07184941 -0.5986606  -1.2589922   1.3834332  -0.4631258  -0.0143058\n",
      "   1.3784105  -0.17111985 -0.5250572   0.05719865]\n",
      " [ 0.2257565   1.0226068  -1.2478795  -0.10247973  0.8146244   0.63160044\n",
      "   0.24853991 -1.3374548  -0.4314926   0.18257435]\n",
      " [-0.5786326   0.03563658  0.50119114 -0.9846781  -1.2987871  -0.46859214\n",
      "  -1.1324059  -0.9277334   1.114755   -0.38899568]\n",
      " [-0.8125486   0.7295272  -1.1358273   0.7067225  -0.08729815  0.28388622\n",
      "  -1.0181171  -0.9129057   0.41915116 -1.3041313 ]\n",
      " [-0.72632396  0.12252925 -0.789423   -0.34263298  1.2199405   1.2289668\n",
      "   0.19285792  0.09670611 -1.4016957   1.3807755 ]\n",
      " [ 0.21099952  0.84296197  0.17785525  1.0902199   0.24326368  0.60342157\n",
      "  -1.0154784  -0.20672445  0.5601989  -1.1423565 ]\n",
      " [-0.1744962  -0.96442896  0.02016308  0.9217777  -1.1842884   0.8669768\n",
      "   0.188167    0.25814882 -0.8722658  -0.184571  ]\n",
      " [-0.58968717 -1.3361163  -1.3559737  -0.13549186  0.7074761   0.16554135\n",
      "  -0.33193675 -0.95902413  0.9773251   0.28618646]\n",
      " [ 0.8168368   1.0069338   0.2980647   0.8120573   0.33439398 -1.3834785\n",
      "   0.7236575  -0.9359987  -0.11986326  0.03791492]\n",
      " [-0.04616781  0.9950203  -0.93954736 -1.4023463   1.0076703   0.70115006\n",
      "  -0.1251121  -0.24010214 -1.1073682  -0.466098  ]\n",
      " [-1.1711357   0.6235916  -1.2219105  -0.8495863   0.21315876 -0.59567434\n",
      "   0.4499351   0.877088   -0.42988294 -1.1746566 ]\n",
      " [ 0.9052518   0.82305413 -0.30793995  1.0530753  -0.3350653  -0.70121515\n",
      "   0.9517279   0.6829712   0.021961    0.4169972 ]\n",
      " [-0.8286787   1.1433063   1.34624    -0.52873015  1.0561768  -0.5481398\n",
      "  -1.3716362  -1.3024926  -0.9111952  -1.2451749 ]\n",
      " [-0.7007167   1.1949453  -0.12178374 -1.0684144   0.8953577  -0.27890077\n",
      "  -1.374038    1.0309778  -0.65212107  0.6041616 ]\n",
      " [-0.41671127  0.85033554  0.9956937   0.11021812  0.17071633 -1.090667\n",
      "  -0.35352436 -0.20586753  0.0323847   1.1319041 ]\n",
      " [-0.57724357 -0.29920638  0.8473428  -0.25345725 -0.91049975  0.9830631\n",
      "   0.20014311 -1.2711296   1.4126085  -0.7836185 ]\n",
      " [ 0.33140314 -0.3813053   0.87479854  0.36855942  0.92807806 -0.61179185\n",
      "  -0.65067554  0.29196525  1.2669817   0.59893304]\n",
      " [-0.6835899  -1.09117    -0.11925645  1.3718569   0.5217264  -0.88626987\n",
      "  -1.3095884   1.3078063   1.0362304   0.9473977 ]\n",
      " [ 1.3403294   0.28585318  1.2450281  -1.020577   -1.1153692  -0.36974183\n",
      "   0.7701616  -0.51676726  0.3988193  -1.4179881 ]\n",
      " [ 0.12558182 -0.46876907  1.1499959   1.2733175  -0.33480215 -0.30014277\n",
      "   1.1478453  -1.274677   -0.2733839  -1.0685192 ]\n",
      " [-1.1933529   0.8204468  -0.5646385   0.2428593   1.0934874   1.1002074\n",
      "   0.291683    0.41960078 -1.2810166  -0.5851212 ]\n",
      " [ 0.5540868  -0.89847493  0.8754677   0.04265632  0.74336636 -0.93095225\n",
      "  -1.2059187  -0.05179875  0.08336637  0.56718576]\n",
      " [-0.8530206   0.4951393   0.84733146 -1.3240389   1.3387605   1.3735334\n",
      "   0.1463722  -1.257097   -0.4471512  -1.3856027 ]\n",
      " [ 0.8692393  -0.8438747  -1.0307364   0.57754576 -1.2771982  -0.7032241\n",
      "   0.02985122  1.4309317  -1.0213083  -0.14586496]\n",
      " [ 0.29308766 -1.1635847  -0.61039996  0.63794845  0.14679195  0.9782372\n",
      "   0.23209819 -0.9113544   0.3337157   1.1180141 ]\n",
      " [ 0.0485086   0.36446193  0.01461711  1.1836219  -0.25048542  0.10247836\n",
      "  -0.454645   -1.0702492   0.47043446  1.2587641 ]\n",
      " [ 0.32570398  0.9902608  -0.815036    1.1648681  -1.4164022  -0.7921985\n",
      "  -1.0630885   1.1774977   1.1852632   0.23419741]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[-2.020863   -1.8768997   1.3279725   1.1404593  -2.0226498  -0.69828486]\n",
      " [ 1.3384582  -1.805413    0.18534032  1.2478856  -1.1143895   0.3258654 ]\n",
      " [-0.11421985  0.27738363 -0.29032794  0.9491154   1.0691395   1.256012  ]\n",
      " [-2.26665     0.8761109  -0.11159483 -1.9587522   0.559445    1.6554363 ]\n",
      " [ 1.1458421  -0.8741465  -2.117068   -2.2666097   0.28965366 -1.6614757 ]\n",
      " [-1.1371111  -1.2947417  -2.354707   -1.7063811  -2.283402    2.3604991 ]\n",
      " [-0.6834796   1.594444   -0.42994714 -1.2091703  -1.289848    1.3379877 ]\n",
      " [ 0.8389841   1.0108107   1.7301011   0.10802037 -0.2803703   0.26331252]\n",
      " [ 0.74461967  1.4136195   1.92172    -0.9351899  -1.7851403   1.2292845 ]\n",
      " [ 0.1314554   1.3949285  -0.3432906   1.6600025   0.1829966  -1.222668  ]]\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "***************************\n",
      "iter 0: accuracy 0.21875\n",
      "iter 100: accuracy 0.40625\n",
      "iter 200: accuracy 0.46875\n",
      "iter 300: accuracy 0.5\n",
      "iter 400: accuracy 0.53125\n",
      "iter 500: accuracy 0.53125\n",
      "iter 600: accuracy 0.53125\n",
      "iter 700: accuracy 0.53125\n",
      "iter 800: accuracy 0.53125\n",
      "iter 900: accuracy 0.53125\n",
      "iter 1000: accuracy 0.5625\n",
      "iter 1100: accuracy 0.5625\n",
      "iter 1200: accuracy 0.5625\n",
      "iter 1300: accuracy 0.5625\n",
      "iter 1400: accuracy 0.5625\n",
      "iter 1500: accuracy 0.59375\n",
      "iter 1600: accuracy 0.59375\n",
      "iter 1700: accuracy 0.59375\n",
      "iter 1800: accuracy 0.59375\n",
      "iter 1900: accuracy 0.59375\n",
      "iter 2000: accuracy 0.59375\n",
      "iter 2100: accuracy 0.59375\n",
      "iter 2200: accuracy 0.59375\n",
      "iter 2300: accuracy 0.59375\n",
      "iter 2400: accuracy 0.59375\n",
      "iter 2500: accuracy 0.59375\n",
      "iter 2600: accuracy 0.625\n",
      "iter 2700: accuracy 0.625\n",
      "iter 2800: accuracy 0.625\n",
      "iter 2900: accuracy 0.65625\n",
      "iter 3000: accuracy 0.65625\n",
      "iter 3100: accuracy 0.6875\n",
      "iter 3200: accuracy 0.6875\n",
      "iter 3300: accuracy 0.6875\n",
      "iter 3400: accuracy 0.65625\n",
      "iter 3500: accuracy 0.65625\n",
      "iter 3600: accuracy 0.65625\n",
      "iter 3700: accuracy 0.65625\n",
      "iter 3800: accuracy 0.65625\n",
      "iter 3900: accuracy 0.65625\n",
      "iter 4000: accuracy 0.65625\n",
      "iter 4100: accuracy 0.65625\n",
      "iter 4200: accuracy 0.6875\n",
      "iter 4300: accuracy 0.6875\n",
      "iter 4400: accuracy 0.6875\n",
      "iter 4500: accuracy 0.6875\n",
      "iter 4600: accuracy 0.6875\n",
      "iter 4700: accuracy 0.6875\n",
      "iter 4800: accuracy 0.6875\n",
      "iter 4900: accuracy 0.6875\n",
      "********* AFTER **********\n",
      "[[ 0.31106687 -3.8457117   0.47588217  1.0514201  -0.35866028 -0.10578192\n",
      "  -2.800939    0.4746802  -2.8489954  -2.12224   ]\n",
      " [-0.21867697  1.2932494  -0.11584021  0.16695356  3.2356293   1.9050393\n",
      "  -1.2561027  -1.1009799   0.802198    1.0146898 ]\n",
      " [ 0.03579833 -0.86323726 -0.28101853  0.6412965   1.112424    0.45684636\n",
      "  -2.0990384   0.8139865   3.3221452   0.50667715]\n",
      " [ 1.1147425  -0.09018723  0.37485456 -0.34026223 -0.8334732   1.4889703\n",
      "  -1.8540109   1.5789847   1.1712273   0.4519364 ]\n",
      " [-0.4123196  -1.4299246  -0.20056899  1.3521743  -1.7797627   0.20683739\n",
      "  -0.851116    1.2212508  -1.2524035  -2.1324701 ]\n",
      " [ 0.4237336   0.69281495  1.4316111  -0.8957232   1.3725731   2.4378366\n",
      "   0.8811841  -0.17739858  1.4602513  -0.7911164 ]\n",
      " [-0.704818    0.47556037  0.20332262  0.45399383 -1.1294245  -0.26384026\n",
      "  -1.9279708  -0.17391312  1.4147791   1.141842  ]\n",
      " [-1.5505172  -0.86947876 -2.1100497   0.606268   -0.5620941  -0.8459519\n",
      "   1.2310883   0.997224    2.5740974  -0.508042  ]\n",
      " [-0.56689894 -1.2759715   3.1814682  -0.37471092 -3.1862822  -0.79769695\n",
      "   0.48367992 -0.80979574 -1.5755333  -0.8850546 ]\n",
      " [-1.0289167   1.8981855  -1.4176472   1.4840856   1.7136688   0.43875602\n",
      "   2.3572116  -0.13848811 -0.32327056 -0.9648757 ]\n",
      " [-1.2193556   0.3884183  -0.9505921   0.12036286  0.16145726 -1.5644403\n",
      "  -0.8136963  -1.1938862   0.44618797  2.1307049 ]\n",
      " [-0.9757832  -0.67725533 -0.25941804 -0.7466469  -2.3410664  -0.57395834\n",
      "  -1.3006122  -0.6491431   1.2762742   1.5981199 ]\n",
      " [-0.6414649  -1.5027593  -2.5624418   1.0024296  -1.9257941  -0.2826937\n",
      "  -1.6295127  -1.7535268  -0.5317966  -2.0555124 ]\n",
      " [ 0.23902191  1.1997812  -1.4677454  -0.24700575  1.2997347   2.1049461\n",
      "   0.47461665 -1.4722418   0.2189581   0.5808719 ]\n",
      " [-2.409813   -1.2824475   2.0493548   1.262953   -0.02957039 -1.0213027\n",
      "  -2.9654098   0.3110235   2.2580595   0.77773803]\n",
      " [-2.2228549  -2.1339161   0.2299614   1.1025532  -0.4409799  -0.0394531\n",
      "  -0.70212346  1.4436338   1.0400025   0.91542107]\n",
      " [ 1.4900581  -0.6533291  -2.7382324   0.12652689 -1.7791325   1.7638812\n",
      "  -0.00574137 -1.4987583   1.0404233  -0.44566914]\n",
      " [ 4.853266    4.99821    -2.209739    0.8697233  -0.0499421  -0.03170458\n",
      "   1.386796   -2.0624552   2.6873248  -1.2844213 ]\n",
      " [-1.7654858  -0.16945161 -0.06209773 -1.2248237  -0.05957196 -2.5045447\n",
      "  -1.4443233   0.04458913  0.6730533   1.3766826 ]\n",
      " [-3.0891924  -0.3476589  -1.2339407  -0.6637717   0.43798003 -1.9174125\n",
      "  -0.21078438  1.4560195   0.3613701   0.5820187 ]\n",
      " [ 2.026137    0.8568187   1.2493868   1.3039612  -3.4688213   0.07004838\n",
      "   1.8695366   0.829199   -0.3066442   0.3587973 ]\n",
      " [ 2.181384    5.009735   -0.20804295 -0.47764307  1.0290327  -0.88213336\n",
      "  -0.23749742 -1.5992421   0.89785296 -2.5543563 ]\n",
      " [-1.057522    1.4461247  -0.11131478 -0.83243686 -1.1917375  -2.6275406\n",
      "  -0.98451334  1.2350909   0.7644783  -0.02664167]\n",
      " [-1.7334781   0.22234921  0.71495575  0.3459782  -0.3174773  -2.4891865\n",
      "  -0.2863742   0.00791435 -0.24554558  1.8102196 ]\n",
      " [ 0.11146756 -2.6361873  -1.592759    0.03389844 -2.0562966  -0.31602472\n",
      "   0.6365543  -1.3514143  -0.29295215 -1.3977265 ]\n",
      " [ 2.0960846   1.2698884  -0.48037592  0.4337339   2.104892    0.8649051\n",
      "  -0.8905134  -0.62499356  0.95910645  2.5185392 ]\n",
      " [-0.6591925  -1.0217925   0.95159394  1.5432492   0.24875562 -1.7789061\n",
      "  -2.6667442   2.2346892   2.151018    1.1476201 ]\n",
      " [ 1.194765    0.3336505   1.3543681  -0.8127764  -1.0850751  -1.406117\n",
      "  -0.13511874  0.64461136  1.2157702  -2.03396   ]\n",
      " [ 1.692475   -1.0519819   0.019286    1.525583   -1.2831812  -0.44929913\n",
      "   2.2580998  -1.7957327  -2.097784   -0.81468415]\n",
      " [ 1.0407374   3.3873942  -2.6344306   0.2966018   2.3852546   0.29100925\n",
      "   1.202917   -0.9191333  -1.0324973  -0.43489334]\n",
      " [-1.0058048  -0.08374157  2.483036    0.23680905  0.15298976 -1.6085006\n",
      "  -0.9615114   0.8025525   0.37060374  1.3492025 ]\n",
      " [-1.5106086   1.3080312   1.1796424  -1.0965887   1.0279186   1.3450813\n",
      "   0.7395661  -0.2239719  -0.38803983 -1.326827  ]\n",
      " [ 1.6262224  -1.36352     0.16451542  0.80932814 -2.7334154  -0.88593787\n",
      "   1.8036556   1.1958658  -2.8416424  -0.62892497]\n",
      " [ 1.0107346   0.711149   -1.4003111   0.67593884  1.9345373  -0.8514783\n",
      "   2.703975   -1.8552771   0.22688149 -1.1120465 ]\n",
      " [-0.5543381   2.139464    0.90892154  1.3815813  -0.7212631  -2.6226885\n",
      "  -0.15565424 -0.18233559  0.46921962  1.5780644 ]\n",
      " [-0.31294656  2.3730202  -0.53828967  1.3895235  -1.5987482  -0.8463338\n",
      "  -0.2183922   1.766637    0.7391037  -0.08841731]]\n",
      "[-2.0770235 -3.7970343  4.0048018  0.9170942  2.0551682  6.2012625\n",
      "  1.3070939 -2.0542464 -4.690136   1.3902318]\n",
      "[[-4.5452585  -4.3802533   4.925754    4.9856706  -5.2533345   0.14788663]\n",
      " [ 4.610374   -6.191864    1.1808834   5.8344865  -5.232719   -0.02474148]\n",
      " [-4.9126735   1.3009671  -3.413773    0.6561464   7.3971467   2.0967736 ]\n",
      " [-2.5916696   0.75970036  0.15277189 -3.8172686   3.1086328   1.1505895 ]\n",
      " [ 8.38376    -4.460266   -1.108696   -5.5661273   0.95275825 -3.639799  ]\n",
      " [-1.8755438  -4.21755    -4.111676    4.3945274  -4.218567    3.6587212 ]\n",
      " [-1.1355822   0.9363388  -2.7236063  -3.2809684   0.81360614  4.713241  ]\n",
      " [-0.4152612   6.1176424   0.9068446  -0.3446542  -2.048147   -0.55644894]\n",
      " [ 1.869324    3.726042    6.463671   -0.7599145  -6.886874   -1.8421994 ]\n",
      " [ 2.0838485   3.2659142  -5.9337735   0.9511277   4.0629296  -2.6390362 ]]\n",
      "[-0.3237197   0.07495797  0.05374665 -2.0497682   3.2096593  -0.9647571 ]\n",
      "**************************\n",
      "Model saved in path: /save/model-PartA-5000-32.ckpt\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    train_acc = []\n",
    "\n",
    "    print(\"********* BEFORE **********\")\n",
    "    print(W.eval())\n",
    "    print(b.eval())\n",
    "    print(V.eval())\n",
    "    print(c.eval())\n",
    "    print(\"***************************\")\n",
    "    for i in range(EPOCHS):\n",
    "    #     for j in range(BATCH_SIZE):\n",
    "    #         np.random.seed()\n",
    "    #         rand_index = np.random.choice(a=len(trainX), size=BATCH_SIZE)\n",
    "    #         x_batch = trainX[rand_index]  # Transpose to the correct shape\n",
    "    #         y_batch = trainY[rand_index]\n",
    "    #         train_op.run(feed_dict={x: x_batch, d: y_batch})\n",
    "\n",
    "    #     train_acc.append(accuracy.eval(feed_dict={x: x_batch, d: y_batch}))\n",
    "\n",
    "\n",
    "        for j in range(len(X)): # X[j]: One batch with 32 records\n",
    "            train_op.run(feed_dict={x: X[j], d: y[j]})\n",
    "        train_acc.append(accuracy.eval(feed_dict={x: X[j], d: y[j]}))\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print('iter %d: accuracy %g'%(i, train_acc[i]))\n",
    "\n",
    "    print(\"********* AFTER **********\")\n",
    "    print(W.eval())\n",
    "    print(b.eval())\n",
    "    print(V.eval())\n",
    "    print(c.eval())\n",
    "    print(\"**************************\")\n",
    "\n",
    "    save_path = saver.save(sess, \"/save/model-PartA-5000-32.ckpt\")\n",
    "    print(\"Model saved in path: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saver = tf.train.Saver()\n",
    "# save_path = saver.save(sess, \"/model-PartA-5000-32.ckpt\")\n",
    "# print(\"Model saved in path: %s\" % save_path)\n",
    "# print(\"********* RESULT **********\")\n",
    "# print(W.eval())\n",
    "# print(b.eval())\n",
    "# print(V.eval())\n",
    "# print(c.eval())\n",
    "# print(\"***************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "del saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Blas GEMM launch failed : a.shape=(2000, 36), b.shape=(36, 10), m=2000, n=10, k=36\n\t [[Node: Hidden_layer/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_x_0_1/_3, Hidden_layer/Weight_1/read)]]\n\t [[Node: Output_layer/add/_7 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_35_Output_layer/add\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'Hidden_layer/MatMul', defined at:\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-12-8c37576b09b6>\", line 4, in <module>\n    z = tf.matmul(x, W) + b #syn_input_1\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 2018, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 4750, in mat_mul\n    name=name)\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInternalError (see above for traceback): Blas GEMM launch failed : a.shape=(2000, 36), b.shape=(36, 10), m=2000, n=10, k=36\n\t [[Node: Hidden_layer/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_x_0_1/_3, Hidden_layer/Weight_1/read)]]\n\t [[Node: Output_layer/add/_7 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_35_Output_layer/add\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1263\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Blas GEMM launch failed : a.shape=(2000, 36), b.shape=(36, 10), m=2000, n=10, k=36\n\t [[Node: Hidden_layer/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_x_0_1/_3, Hidden_layer/Weight_1/read)]]\n\t [[Node: Output_layer/add/_7 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_35_Output_layer/add\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-910bbe4684bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0moutput_2_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtestX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtestY\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_2_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maccuracy_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 877\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1100\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1101\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1272\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1273\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1274\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1289\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1291\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1293\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Blas GEMM launch failed : a.shape=(2000, 36), b.shape=(36, 10), m=2000, n=10, k=36\n\t [[Node: Hidden_layer/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_x_0_1/_3, Hidden_layer/Weight_1/read)]]\n\t [[Node: Output_layer/add/_7 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_35_Output_layer/add\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'Hidden_layer/MatMul', defined at:\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-12-8c37576b09b6>\", line 4, in <module>\n    z = tf.matmul(x, W) + b #syn_input_1\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 2018, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 4750, in mat_mul\n    name=name)\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\lzcai\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInternalError (see above for traceback): Blas GEMM launch failed : a.shape=(2000, 36), b.shape=(36, 10), m=2000, n=10, k=36\n\t [[Node: Hidden_layer/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_x_0_1/_3, Hidden_layer/Weight_1/read)]]\n\t [[Node: Output_layer/add/_7 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_35_Output_layer/add\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "# print(\"********* RESULT **********\")\n",
    "# print(W.eval())\n",
    "# print(b.eval())\n",
    "# print(V.eval())\n",
    "# print(c.eval())\n",
    "# print(\"***************************\")\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    output_2_, accuracy_ = sess.run([f, accuracy], feed_dict={x: testX, d: testY})\n",
    "    print(output_2_, '\\n',accuracy_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /save/model-PartA-5000-32.ckpt\n",
      "Model restored.\n",
      "W : [[ 0.31106687 -3.8457117   0.47588217  1.0514201  -0.35866028 -0.10578192\n",
      "  -2.800939    0.4746802  -2.8489954  -2.12224   ]\n",
      " [-0.21867697  1.2932494  -0.11584021  0.16695356  3.2356293   1.9050393\n",
      "  -1.2561027  -1.1009799   0.802198    1.0146898 ]\n",
      " [ 0.03579833 -0.86323726 -0.28101853  0.6412965   1.112424    0.45684636\n",
      "  -2.0990384   0.8139865   3.3221452   0.50667715]\n",
      " [ 1.1147425  -0.09018723  0.37485456 -0.34026223 -0.8334732   1.4889703\n",
      "  -1.8540109   1.5789847   1.1712273   0.4519364 ]\n",
      " [-0.4123196  -1.4299246  -0.20056899  1.3521743  -1.7797627   0.20683739\n",
      "  -0.851116    1.2212508  -1.2524035  -2.1324701 ]\n",
      " [ 0.4237336   0.69281495  1.4316111  -0.8957232   1.3725731   2.4378366\n",
      "   0.8811841  -0.17739858  1.4602513  -0.7911164 ]\n",
      " [-0.704818    0.47556037  0.20332262  0.45399383 -1.1294245  -0.26384026\n",
      "  -1.9279708  -0.17391312  1.4147791   1.141842  ]\n",
      " [-1.5505172  -0.86947876 -2.1100497   0.606268   -0.5620941  -0.8459519\n",
      "   1.2310883   0.997224    2.5740974  -0.508042  ]\n",
      " [-0.56689894 -1.2759715   3.1814682  -0.37471092 -3.1862822  -0.79769695\n",
      "   0.48367992 -0.80979574 -1.5755333  -0.8850546 ]\n",
      " [-1.0289167   1.8981855  -1.4176472   1.4840856   1.7136688   0.43875602\n",
      "   2.3572116  -0.13848811 -0.32327056 -0.9648757 ]\n",
      " [-1.2193556   0.3884183  -0.9505921   0.12036286  0.16145726 -1.5644403\n",
      "  -0.8136963  -1.1938862   0.44618797  2.1307049 ]\n",
      " [-0.9757832  -0.67725533 -0.25941804 -0.7466469  -2.3410664  -0.57395834\n",
      "  -1.3006122  -0.6491431   1.2762742   1.5981199 ]\n",
      " [-0.6414649  -1.5027593  -2.5624418   1.0024296  -1.9257941  -0.2826937\n",
      "  -1.6295127  -1.7535268  -0.5317966  -2.0555124 ]\n",
      " [ 0.23902191  1.1997812  -1.4677454  -0.24700575  1.2997347   2.1049461\n",
      "   0.47461665 -1.4722418   0.2189581   0.5808719 ]\n",
      " [-2.409813   -1.2824475   2.0493548   1.262953   -0.02957039 -1.0213027\n",
      "  -2.9654098   0.3110235   2.2580595   0.77773803]\n",
      " [-2.2228549  -2.1339161   0.2299614   1.1025532  -0.4409799  -0.0394531\n",
      "  -0.70212346  1.4436338   1.0400025   0.91542107]\n",
      " [ 1.4900581  -0.6533291  -2.7382324   0.12652689 -1.7791325   1.7638812\n",
      "  -0.00574137 -1.4987583   1.0404233  -0.44566914]\n",
      " [ 4.853266    4.99821    -2.209739    0.8697233  -0.0499421  -0.03170458\n",
      "   1.386796   -2.0624552   2.6873248  -1.2844213 ]\n",
      " [-1.7654858  -0.16945161 -0.06209773 -1.2248237  -0.05957196 -2.5045447\n",
      "  -1.4443233   0.04458913  0.6730533   1.3766826 ]\n",
      " [-3.0891924  -0.3476589  -1.2339407  -0.6637717   0.43798003 -1.9174125\n",
      "  -0.21078438  1.4560195   0.3613701   0.5820187 ]\n",
      " [ 2.026137    0.8568187   1.2493868   1.3039612  -3.4688213   0.07004838\n",
      "   1.8695366   0.829199   -0.3066442   0.3587973 ]\n",
      " [ 2.181384    5.009735   -0.20804295 -0.47764307  1.0290327  -0.88213336\n",
      "  -0.23749742 -1.5992421   0.89785296 -2.5543563 ]\n",
      " [-1.057522    1.4461247  -0.11131478 -0.83243686 -1.1917375  -2.6275406\n",
      "  -0.98451334  1.2350909   0.7644783  -0.02664167]\n",
      " [-1.7334781   0.22234921  0.71495575  0.3459782  -0.3174773  -2.4891865\n",
      "  -0.2863742   0.00791435 -0.24554558  1.8102196 ]\n",
      " [ 0.11146756 -2.6361873  -1.592759    0.03389844 -2.0562966  -0.31602472\n",
      "   0.6365543  -1.3514143  -0.29295215 -1.3977265 ]\n",
      " [ 2.0960846   1.2698884  -0.48037592  0.4337339   2.104892    0.8649051\n",
      "  -0.8905134  -0.62499356  0.95910645  2.5185392 ]\n",
      " [-0.6591925  -1.0217925   0.95159394  1.5432492   0.24875562 -1.7789061\n",
      "  -2.6667442   2.2346892   2.151018    1.1476201 ]\n",
      " [ 1.194765    0.3336505   1.3543681  -0.8127764  -1.0850751  -1.406117\n",
      "  -0.13511874  0.64461136  1.2157702  -2.03396   ]\n",
      " [ 1.692475   -1.0519819   0.019286    1.525583   -1.2831812  -0.44929913\n",
      "   2.2580998  -1.7957327  -2.097784   -0.81468415]\n",
      " [ 1.0407374   3.3873942  -2.6344306   0.2966018   2.3852546   0.29100925\n",
      "   1.202917   -0.9191333  -1.0324973  -0.43489334]\n",
      " [-1.0058048  -0.08374157  2.483036    0.23680905  0.15298976 -1.6085006\n",
      "  -0.9615114   0.8025525   0.37060374  1.3492025 ]\n",
      " [-1.5106086   1.3080312   1.1796424  -1.0965887   1.0279186   1.3450813\n",
      "   0.7395661  -0.2239719  -0.38803983 -1.326827  ]\n",
      " [ 1.6262224  -1.36352     0.16451542  0.80932814 -2.7334154  -0.88593787\n",
      "   1.8036556   1.1958658  -2.8416424  -0.62892497]\n",
      " [ 1.0107346   0.711149   -1.4003111   0.67593884  1.9345373  -0.8514783\n",
      "   2.703975   -1.8552771   0.22688149 -1.1120465 ]\n",
      " [-0.5543381   2.139464    0.90892154  1.3815813  -0.7212631  -2.6226885\n",
      "  -0.15565424 -0.18233559  0.46921962  1.5780644 ]\n",
      " [-0.31294656  2.3730202  -0.53828967  1.3895235  -1.5987482  -0.8463338\n",
      "  -0.2183922   1.766637    0.7391037  -0.08841731]]\n",
      "b : [-2.0770235 -3.7970343  4.0048018  0.9170942  2.0551682  6.2012625\n",
      "  1.3070939 -2.0542464 -4.690136   1.3902318]\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    # Restore variables from disk.\n",
    "    saver.restore(sess, \"/save/model-PartA-5000-32.ckpt\")\n",
    "    print(\"Model restored.\")\n",
    "    # Check the values of the variables\n",
    "    print(\"W : %s\" % W.eval())\n",
    "    print(\"b : %s\" % b.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot learning curves\n",
    "plt.figure\n",
    "(1)\n",
    "plt.plot(range(EPOCHS), train_acc)\n",
    "plt.xlabel(str(EPOCHS) + ' iterations')\n",
    "plt.ylabel('Train accuracy')\n",
    "plt.savefig(\"PartA-5000-32-random.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[109   7  20  43  31  58  24  51 108 125  96  70  23   1 118 113  21 112\n",
      "  77  52  41  41  22  29  43  54  38 128  45  70  17  59]\n",
      "[ 32  13  94 116  59   9  12 108 105  47 120  81  99  51  52 117  62  97\n",
      "  14  36  53  31  75  81   7  12  55  81  65  42  20  41]\n",
      "[ 39 101   2 127 131  14   9  46  32 114  59  72  72  53 116  51  18  68\n",
      "  83  65 120 131  12 112 136  10 109 116 127   9  18  38]\n",
      "[101 113 135  37  31  49 137  52 110  36  74  52  57  94  71 118 110  70\n",
      "  61 120  50 112  40 128  44 112  51 103 135 111  45   6]\n",
      "[  9  32 100  90  25  50  97 122  67  77 102  60  67  95  33  34  51 102\n",
      "  87  95  51  78  47  10  37  70  36  27  15 129  36  76]\n",
      "[117   0  72  52   6 107  83  20   0  40  47  44  36  89 136 135  49  81\n",
      "  17  15  93  10  33 111 101  20  21  19  59  94  76  80]\n",
      "[130  64   1  66 126 125  40  66  48 100  93  67  83 101 130 103  75   1\n",
      "  25  81  56  64  47 121  75 124  59 137  52   0  12  51]\n",
      "[ 95 122  14 113   6   4 126 110  78  57  49  17 135  56 104  86  76  84\n",
      " 109 128 136  83  92 123 120  86  28  91  95  70  16  18]\n",
      "[ 48   4 132 132  78  44  72  60  55 129 133  51  50 110  87  58  62  64\n",
      " 137  50  49  96  56  54  60  91  89 128 125  98  11  89]\n",
      "[ 77  80  56  68 126   7  35  44  72  24 132 111   2 100  72  28  10 109\n",
      "  59 121 127  67  28   2  59  53  23  76 120  89  40  18]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    np.random.seed()\n",
    "    rand_index = np.random.choice(int(len(trainX)/BATCH_SIZE), size=BATCH_SIZE)\n",
    "    print(rand_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5       , 0.49090909, 0.30952381, 0.2892562 , 0.4516129 ,\n",
       "       0.41818182, 0.29473684, 0.28125   , 0.375     , 0.40776699,\n",
       "       0.29473684, 0.28125   , 0.5       , 0.5       , 0.2826087 ,\n",
       "       0.28813559, 0.484375  , 0.50485437, 0.3253012 , 0.26829268,\n",
       "       0.49230769, 0.50485437, 0.32222222, 0.272     , 0.484375  ,\n",
       "       0.5       , 0.27586207, 0.275     , 0.49230769, 0.47524752,\n",
       "       0.32631579, 0.296875  , 0.421875  , 0.4368932 , 0.32631579,\n",
       "       0.296875  ])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
