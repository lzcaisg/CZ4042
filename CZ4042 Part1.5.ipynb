{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lzcai/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import os\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Values\n",
    "NUM_FEATURES = 36\n",
    "NUM_CLASSES = 6\n",
    "NUM_HIDDEN = 10\n",
    "\n",
    "LEARNING_RATE = 0.01\n",
    "EPOCHS = 5000\n",
    "BATCH_SIZE = 32\n",
    "SEED = 10\n",
    "BETA = pow(10, -6)\n",
    "np.random.seed(SEED)\n",
    "DROP = True\n",
    "\n",
    "TRAIN_FILE_NAME = 'sat_train.txt'\n",
    "TEST_FILE_NAME = 'sat_test.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data\n",
    "def scale(X, X_min, X_max):\n",
    "    return (X - X_min)/(X_max-X_min)\n",
    "\n",
    "def process_inputs_from_file(fileName): # Read in data\n",
    "    inputs = np.loadtxt(fileName, delimiter=' ')\n",
    "    X, _Y = inputs[:, :NUM_FEATURES], inputs[:, -1].astype(int)\n",
    "    X = scale(X, np.min(X, axis=0), np.max(X, axis=0))\n",
    "    _Y[_Y == 7] = 6 # Actually dont have, just in case have error data\n",
    "\n",
    "    Y = np.zeros((_Y.shape[0], NUM_CLASSES))\n",
    "    Y[np.arange(_Y.shape[0]), _Y - 1] = 1 #one hot matrix\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainY = process_inputs_from_file(TRAIN_FILE_NAME)\n",
    "testX, testY = process_inputs_from_file(TEST_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of:\n",
      "- Training-set\t\t 4435\n",
      "- Test-set\t\t 2000\n"
     ]
    }
   ],
   "source": [
    "print (\"Size of:\")\n",
    "print(\"- Training-set\\t\\t\",len(trainX))\n",
    "print(\"- Test-set\\t\\t\",len(testX))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 layers in this graph, namely one input-layer(X), one hidden-layer(W, b) and one output-layer(V, c).\n",
    "\n",
    "The output does not scale to [0, 1] and I dont know why. --- Solved 07 Oct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholder Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, NUM_FEATURES], name='x')\n",
    "d = tf.placeholder(tf.float32, [None, NUM_CLASSES], name='d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(feature_no, neuron_no, name, logistic = True):\n",
    "    # From eg.5.2\n",
    "    n_in = feature_no\n",
    "    n_out = neuron_no\n",
    "    W_values = np.asarray(np.random.uniform(low=-np.sqrt(6. / (n_in + n_out)),\n",
    "                                            high=np.sqrt(6. / (n_in + n_out)),\n",
    "                                            size=(n_in, n_out)))\n",
    "    if logistic == True:\n",
    "        W_values *= 4\n",
    "    return(tf.Variable(W_values, dtype=tf.float32, name=name))\n",
    "\n",
    "def init_bias(neuron_no, name):\n",
    "    # From eg.5.2\n",
    "    return(tf.Variable(np.zeros(neuron_no), dtype=tf.float32, name=name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"Hidden_layer\"):\n",
    "    W = init_weights(NUM_FEATURES, NUM_HIDDEN, name=\"Weight_1\")\n",
    "    b = init_bias(NUM_HIDDEN, name=\"Bias_1\")\n",
    "    z = tf.matmul(x, W) + b #syn_input_1\n",
    "    h = tf.nn.sigmoid(z) #out_1\n",
    "\n",
    "with tf.variable_scope(\"Output_layer\"):\n",
    "    V = init_weights(NUM_HIDDEN, NUM_CLASSES, name=\"Weight_2\")\n",
    "    c = init_bias(NUM_CLASSES, name=\"Bias_2\" )\n",
    "    u = tf.matmul(h, V) + c #syn_out_2\n",
    "    y = tf.nn.sigmoid(u) #out_2  # Consider to change to sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_cross_entropy(labels, logits):\n",
    "    return tf.nn.softmax_cross_entropy_with_logits_v2(labels=labels, logits=logits)\n",
    "\n",
    "def setup_correct_prediction(labels, logits):\n",
    "    return tf.cast(tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1)), tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = setup_cross_entropy(labels=d, logits=y)\n",
    "regularization = tf.nn.l2_loss(V) + tf.nn.l2_loss(W) \n",
    "J = tf.reduce_mean(cross_entropy + BETA * regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = setup_correct_prediction(labels=d, logits=y)\n",
    "accuracy = tf.reduce_mean(correct_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(LEARNING_RATE)\n",
    "train_op = optimizer.minimize(J)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Exist\n"
     ]
    }
   ],
   "source": [
    "# save_dir = \"Z:\\Github\\CZ4042\\save\"\n",
    "save_dir = \"/Users/lzcai/CZ4042 Project/CZ4042/save-mac\"\n",
    "if not os.path.exists(save_dir):\n",
    "    print(\"Not Exist\")\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_str = \"-Drop\" if DROP else \"-Not_Drop\"\n",
    "\n",
    "save_path = os.path.join(save_dir, str(EPOCHS)+ '-'+ str(BATCH_SIZE)+'-sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/lzcai/CZ4042 Project/CZ4042/save-mac/5000-32-sigmoid'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create TensorFlow Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_variables():\n",
    "    session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper-function to perform optimization iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper-function to generate next_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper-function to plot train accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train(EPOCHS, BATCH_SIZE, train_acc_record, error=False):\n",
    "    if error:\n",
    "        train_acc_record = [1-tmp for tmp in train_acc_record]\n",
    "        yLabel = \"Train Error\"\n",
    "    else:\n",
    "        yLabel = 'Train Accuracy'\n",
    "        \n",
    "    plt.figure(1)\n",
    "    plt.plot(range(EPOCHS), train_acc_record)\n",
    "    plt.xlabel(str(EPOCHS) + ' iterations')\n",
    "    plt.ylabel(yLabel)\n",
    "    plt.savefig(\"PartA-Train\"+str(EPOCHS)+'-'+str(BATCH_SIZE)+\".png\")\n",
    "    plt.show()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_test(EPOCHS, BATCH_SIZE, test_acc_record, error=False):\n",
    "    if error:\n",
    "        test_acc_record = [1-tmp for tmp in test_acc_record]\n",
    "        yLabel = \"Test Error\"\n",
    "    else:\n",
    "        yLabel = 'Test Accuracy'\n",
    "    \n",
    "    plt.figure(1)\n",
    "    plt.plot(range(EPOCHS), test_acc_record)\n",
    "    plt.xlabel(str(EPOCHS) + ' iterations')\n",
    "    plt.ylabel('Test accuracy')\n",
    "    plt.savefig(\"PartA-Test\"+str(EPOCHS)+'-'+str(BATCH_SIZE)+\".png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== For test after training only- =========== #\n",
    "# plot_train(EPOCHS, BATCH_SIZE, train_acc_record, test = True)\n",
    "# plot_test(test_count, BATCH_SIZE, test_acc_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper-function of validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_accuracy(testX, testY):\n",
    "    output_2_, accuracy_ = session.run([y, accuracy], feed_dict={x: testX, d: testY})\n",
    "    print(output_2_, '\\n',accuracy_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the optimal batch size by training the neural network by evaluating the performances for different batch sizes.\n",
    "\n",
    "- Plot the **Training Errors** and **Test Accuracies** against the **number of epochs** for the 3-layer network for **different batch sizes**. Limit search space to *S={4, 8, 16, 32, 64}*.\n",
    "\n",
    "- Plot the **time taken to train** the network for **one epoch** against **different batch sizes**\n",
    "\n",
    "- State the rationale for selecting the optimal batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc_backup = []\n",
    "test_acc_backup = []\n",
    "time_usage_backup = []\n",
    "total_time_backup = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_SIZE= 4\n",
      "iter 0: Train accuracy 0.5 Test accuracy:  0.254 *\n",
      "iter 100: Train accuracy 0.75 Test accuracy:  0.657 *\n",
      "iter 200: Train accuracy 0.5 Test accuracy:  0.783 *\n",
      "iter 300: Train accuracy 1 Test accuracy:  0.793 *\n",
      "iter 400: Train accuracy 0.75 Test accuracy:  0.804 *\n",
      "iter 500: Train accuracy 1 Test accuracy:  0.8085 *\n",
      "iter 600: Train accuracy 1 Test accuracy:  0.809 *\n",
      "iter 700: Train accuracy 0.75 Test accuracy:  0.812 *\n",
      "iter 800: Train accuracy 1 Test accuracy:  0.8115 \n",
      "iter 900: Train accuracy 1 Test accuracy:  0.8135 *\n",
      "iter 1000: Train accuracy 0.75 Test accuracy:  0.8175 *\n",
      "iter 1100: Train accuracy 0.75 Test accuracy:  0.8195 *\n",
      "iter 1200: Train accuracy 0.75 Test accuracy:  0.818 \n",
      "iter 1300: Train accuracy 0.75 Test accuracy:  0.823 *\n",
      "iter 1400: Train accuracy 1 Test accuracy:  0.825 *\n",
      "iter 1500: Train accuracy 0.75 Test accuracy:  0.8255 *\n",
      "iter 1600: Train accuracy 1 Test accuracy:  0.8255 \n",
      "iter 1700: Train accuracy 1 Test accuracy:  0.826 *\n",
      "iter 1800: Train accuracy 1 Test accuracy:  0.8255 \n",
      "iter 1900: Train accuracy 0.75 Test accuracy:  0.8295 *\n",
      "iter 2000: Train accuracy 1 Test accuracy:  0.83 *\n",
      "iter 2100: Train accuracy 0.75 Test accuracy:  0.829 \n",
      "iter 2200: Train accuracy 0.5 Test accuracy:  0.83 \n",
      "iter 2300: Train accuracy 0.75 Test accuracy:  0.83 \n",
      "iter 2400: Train accuracy 1 Test accuracy:  0.83 \n",
      "iter 2500: Train accuracy 0.75 Test accuracy:  0.8305 *\n",
      "iter 2600: Train accuracy 0.75 Test accuracy:  0.833 *\n",
      "iter 2700: Train accuracy 1 Test accuracy:  0.832 \n",
      "iter 2800: Train accuracy 0.75 Test accuracy:  0.834 *\n",
      "iter 2900: Train accuracy 0.75 Test accuracy:  0.8365 *\n",
      "iter 3000: Train accuracy 0.75 Test accuracy:  0.837 *\n",
      "iter 3100: Train accuracy 0.75 Test accuracy:  0.84 *\n",
      "iter 3200: Train accuracy 0.75 Test accuracy:  0.8385 \n",
      "iter 3300: Train accuracy 0.5 Test accuracy:  0.8405 *\n",
      "iter 3400: Train accuracy 1 Test accuracy:  0.8385 \n",
      "iter 3500: Train accuracy 0.75 Test accuracy:  0.8405 \n",
      "iter 3600: Train accuracy 1 Test accuracy:  0.841 *\n",
      "iter 3700: Train accuracy 0.75 Test accuracy:  0.843 *\n",
      "iter 3800: Train accuracy 1 Test accuracy:  0.8415 \n",
      "iter 3900: Train accuracy 1 Test accuracy:  0.8435 *\n",
      "iter 4000: Train accuracy 1 Test accuracy:  0.8415 \n",
      "iter 4100: Train accuracy 1 Test accuracy:  0.841 \n",
      "iter 4200: Train accuracy 0.75 Test accuracy:  0.84 \n",
      "iter 4300: Train accuracy 1 Test accuracy:  0.8415 \n",
      "iter 4400: Train accuracy 0.5 Test accuracy:  0.8415 \n",
      "iter 4500: Train accuracy 0.75 Test accuracy:  0.841 \n",
      "iter 4600: Train accuracy 1 Test accuracy:  0.841 \n",
      "iter 4700: Train accuracy 1 Test accuracy:  0.841 \n",
      "iter 4800: Train accuracy 1 Test accuracy:  0.8405 \n",
      "iter 4900: Train accuracy 1 Test accuracy:  0.8405 \n",
      "iter 4999: Train accuracy 1 Test accuracy:  0.841 \n",
      "Time usage: 1:34:45\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for BATCH_SIZE in [64, 32, 16, 8, 4]:\n",
    "for BATCH_SIZE in [4]:\n",
    "# Counter for total number of iterations performed so far.\n",
    "    init_variables()\n",
    "    print(\"BATCH_SIZE=\", BATCH_SIZE)\n",
    "    total_iterations = 0\n",
    "    train_acc = []\n",
    "    save_path = os.path.join(save_dir, str(EPOCHS)+ '-'+ str(BATCH_SIZE)+'-sigmoid')\n",
    "    \n",
    "    with session.as_default():\n",
    "        # Ensure we update the global variables rather than local copies.\n",
    "\n",
    "        # Start-time used for printing time-usage below.\n",
    "        start_time = time.time()\n",
    "        train_acc_record = []\n",
    "        test_acc_record = []\n",
    "        epoch_time_record = []\n",
    "        \n",
    "        best_test_acc = 0.0\n",
    "        last_improvement = 0\n",
    "        improved_str = \"\"\n",
    "        test_count = 0\n",
    "        \n",
    "        mul = int(len(trainX)/BATCH_SIZE)\n",
    "        for i in range(EPOCHS):\n",
    "            \n",
    "            epoch_start_time = time.time()\n",
    "            for j in range(mul):\n",
    "                x_batch, d_batch = next_batch(BATCH_SIZE, trainX, trainY)\n",
    "                feed_dict_train = {x: x_batch, d: d_batch}\n",
    "                session.run(train_op, feed_dict=feed_dict_train)\n",
    "\n",
    "            train_acc_record.append(accuracy.eval(feed_dict=feed_dict_train))\n",
    "            epoch_end_time = time.time()\n",
    "            epoch_time_diff = epoch_end_time-epoch_start_time\n",
    "            epoch_time_record.append(epoch_time_diff)\n",
    "\n",
    "            if i % 100 == 0 or i == (EPOCHS - 1):\n",
    "                test_count += 1\n",
    "                test_accuracy = session.run(accuracy, feed_dict={x: testX, d: testY})\n",
    "                test_acc_record.append(test_accuracy)\n",
    "                if DROP:\n",
    "                    if test_accuracy > best_test_acc:\n",
    "                        best_test_acc = test_accuracy\n",
    "                        last_improvement = i\n",
    "                        saver.save(sess=session, save_path=save_path)\n",
    "                        improved_str = \"*\"\n",
    "                    else:\n",
    "                        improved_str = ''\n",
    "                else:\n",
    "                    saver.save(sess=session, save_path=save_path)\n",
    "\n",
    "                print('iter %d: Train accuracy %g'%(i, train_acc_record[i]), 'Test accuracy: ',test_accuracy, improved_str)\n",
    "\n",
    "\n",
    "\n",
    "    # Ending time.\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Difference between start and end-times.\n",
    "    time_dif = end_time - start_time\n",
    "\n",
    "    # Print the time-usage.\n",
    "    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))\n",
    "\n",
    "    plot_train(EPOCHS, BATCH_SIZE, train_acc_record, error = True)\n",
    "    plot_test(test_count, BATCH_SIZE, test_acc_record)\n",
    "\n",
    "    train_acc_backup.append(train_acc_record)\n",
    "    test_acc_backup.append(test_acc_record)\n",
    "    time_usage_backup.append(epoch_time_record)\n",
    "    total_time_backup.append(time_dif)\n",
    "            \n",
    "    #=========== Save all the data for EACH TRAINING Has Done ============#\n",
    "    train_acc_filename = \"PartA-Train_Acc-\"+str(EPOCHS)+'-'+str(BATCH_SIZE)+\".out\"\n",
    "    with open(train_acc_filename, 'wb') as fp:\n",
    "        pickle.dump(train_acc_backup, fp)\n",
    "\n",
    "    test_acc_filename = \"PartA-Test_Acc-\"+str(EPOCHS)+'-'+str(BATCH_SIZE)+\".out\"\n",
    "    with open(train_acc_filename, 'wb') as fp:\n",
    "        pickle.dump(test_acc_backup, fp)\n",
    "\n",
    "    time_usage_filename = \"PartA-Time_Usage-\"+str(EPOCHS)+'-'+str(BATCH_SIZE)+\".out\"\n",
    "    with open(time_usage_filename, 'wb') as fp:\n",
    "        pickle.dump(time_usage_backup, fp)\n",
    "\n",
    "    time_usage_filename = \"PartA-Time_Usage-\"+str(EPOCHS)+'-'+str(BATCH_SIZE)+\".out\"\n",
    "    with open(time_usage_filename, 'wb') as fp:\n",
    "        pickle.dump(time_usage_backup, fp)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_usage_backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the optimal **number of hidden neurons** for the 3-layer network designed in part(2):\n",
    "\n",
    "- Plot the **training errors** and **test accuracies** against the **number of epochs** for 3-layer network at hidden layer neurons. Limit the search space to the number of hidden neurons to *S = {5 ,10, 15, 20, 25}*\n",
    "\n",
    "- Plot the **time to train** the network for **one epoch** for different number of hidden neurons/\n",
    "\n",
    "- State the rationale for selecting the optimal number of hidden neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32 # Set to the optimal batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for NUM_HIDDEN in [5 ,10, 15, 20, 25]:\n",
    "# Counter for total number of iterations performed so far.\n",
    "    with tf.variable_scope(\"Hidden_layer\"):\n",
    "        W = init_weights(NUM_FEATURES, NUM_HIDDEN, name=\"Weight_1\")\n",
    "        b = init_bias(NUM_HIDDEN, name=\"Bias_1\")\n",
    "        z = tf.matmul(x, W) + b #syn_input_1\n",
    "        h = tf.nn.sigmoid(z) #out_1\n",
    "\n",
    "    with tf.variable_scope(\"Output_layer\"):\n",
    "        V = init_weights(NUM_HIDDEN, NUM_CLASSES, name=\"Weight_2\")\n",
    "        c = init_bias(NUM_CLASSES, name=\"Bias_2\" )\n",
    "        u = tf.matmul(h, V) + c #syn_out_2\n",
    "        y = tf.nn.sigmoid(u) #out_2  # Consider to change to sigmoid\n",
    "        init_variables()\n",
    "        \n",
    "        \n",
    "    print(\"NUM_NEURONS=\", NUM_HIDDEN)\n",
    "    total_iterations = 0\n",
    "    train_acc = []\n",
    "    save_path = os.path.join(save_dir, str(EPOCHS)+ '-'+ str(NUM_NEURONS)+'-neurons')\n",
    "    \n",
    "    with session.as_default():\n",
    "        # Ensure we update the global variables rather than local copies.\n",
    "\n",
    "        # Start-time used for printing time-usage below.\n",
    "        start_time = time.time()\n",
    "        train_acc_record = []\n",
    "        test_acc_record = []\n",
    "        best_test_acc = 0.0\n",
    "        last_improvement = 0\n",
    "        improved_str = \"\"\n",
    "        test_count = 0\n",
    "        mul = int(len(trainX)/BATCH_SIZE)\n",
    "        for i in range(EPOCHS):\n",
    "            for j in range(mul):\n",
    "                x_batch, d_batch = next_batch(BATCH_SIZE, trainX, trainY)\n",
    "                feed_dict_train = {x: x_batch, d: d_batch}\n",
    "                session.run(train_op, feed_dict=feed_dict_train)\n",
    "\n",
    "            train_acc_record.append(accuracy.eval(feed_dict=feed_dict_train))\n",
    "\n",
    "\n",
    "            if i % 100 == 0 or i == (EPOCHS - 1):\n",
    "                test_count += 1\n",
    "                test_accuracy = session.run(accuracy, feed_dict={x: testX, d: testY})\n",
    "                test_acc_record.append(test_accuracy)\n",
    "                if DROP:\n",
    "                    if test_accuracy > best_test_acc:\n",
    "                        best_test_acc = test_accuracy\n",
    "                        last_improvement = i\n",
    "                        saver.save(sess=session, save_path=save_path)\n",
    "                        improved_str = \"*\"\n",
    "                    else:\n",
    "                        improved_str = ''\n",
    "                else:\n",
    "                    saver.save(sess=session, save_path=save_path)\n",
    "\n",
    "                print('iter %d: Train accuracy %g'%(i, train_acc_record[i]), 'Test accuracy: ',test_accuracy, improved_str)\n",
    "\n",
    "\n",
    "\n",
    "        # Ending time.\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Difference between start and end-times.\n",
    "        time_dif = end_time - start_time\n",
    "\n",
    "        # Print the time-usage.\n",
    "        print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))\n",
    "\n",
    "        plot_train(EPOCHS, BATCH_SIZE, train_acc_record, error = True)\n",
    "        plot_test(test_count, BATCH_SIZE, test_acc_record)\n",
    "        \n",
    "        train_acc_backup.append(train_acc_record)\n",
    "        test_acc_backup.append(test_acc_record)\n",
    "        time_usage_backup.append(time_dif)\n",
    "        \n",
    "        \n",
    "        # Save all the data\n",
    "        train_acc_filename = \"PartA-Train_Acc-\"+str(EPOCHS)+'-'+str(BATCH_SIZE)+\".out\"\n",
    "        with open(train_acc_filename, 'wb') as fp:\n",
    "            pickle.dump(train_acc_backup, fp)\n",
    "            \n",
    "        test_acc_filename = \"PartA-Test_Acc-\"+str(EPOCHS)+'-'+str(BATCH_SIZE)+\".out\"\n",
    "        with open(train_acc_filename, 'wb') as fp:\n",
    "            pickle.dump(test_acc_backup, fp)\n",
    "        \n",
    "        time_usage_filename = \"PartA-Time_Usage-\"+str(EPOCHS)+'-'+str(BATCH_SIZE)+\".out\"\n",
    "        with open(time_usage_filename, 'wb') as fp:\n",
    "            pickle.dump(time_usage_backup, fp)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the optimal **decay parameter** for the 3-layer network designed with optimal hidden neurons in part (3).\n",
    "\n",
    "- Plot the **training errors** against the **number of epochs** for the 3-layer network for different values of **decay parameters** in search space *S = {0, 10^-3, 10^-6, 10^-9, 10^-12}*\n",
    "\n",
    "- Plot the test accuracies against the different values of decay parameter.\n",
    "\n",
    "- State the rationale for selecting the optimal decay parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you are done with the 3-layer network, **design a 4-layer network** with **two hidden-layers**, each consisting of **10 perceptrons**, trained with a **batch size of 32** and **decay parameter 10^-6**.\n",
    "\n",
    "- Plot the **train and test accuracy** of the 4-layer network.\n",
    "\n",
    "- Compare and comment on the performances on 3-layer and 4-layer networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6, 0.6, 0.6]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = [0.4, 0.4, 0.4]\n",
    "tmp = [1-a for a in tmp]\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6, 0.6, 0.6]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
